Seurat Guided Clustering Tutorial
====
For this tutorial, we will be using a slightly modified version of the [Seurat 3kPBMC cells Tutorial](https://satijalab.org/seurat/v3.1/pbmc3k_tutorial.html).  

### Setting up your Seurat object
Seurat is well set up to analyzed data generated by 10x sequencing (it also can do all the other technologies, but its biggest draw it is the easy interaction with 10x pipeline).

First, we need to decided where and how we will analyze our data. Again, this is personal preference, but you should think carefully how you set up your folders to be able to easily access them when you start analyzing several different datasets.
  
For this example, I set up the data analysis folder within my main tutorial folder (`/path/to/folder/202005_scRNA_seq_for_class`). The structure here is as such:
```
/path/to/folder/202005_scRNA_seq_for_class
├── neuron_1k_v3_fastqs
|   ├── #all fastq files
|   ├── run_neuron_1kcells
|   |  ├── SC_RNA_COUNTER_CS
|   |  ├── outs
|   |  |   ├── analysis
|   |  |   ├── filtered_feature_bc_matrix
|   |  |   ├── raw_feature_bc_matrix
├── 202004_1k_v3_neuron_data_analysis
|   ├── 00_input_data
|   |   ├── neuron_1k_filtered_feature_bc_matrix
|   ├── 01_output_data
|   ├── 02_figures
|   ├── 03_rds_files
```
The main output that Seurat will use is the `filtered_feature_bc_matrix` generated by the alignment step. So, I created a sub-folder within my analysis folder called `00_input_data/neuron_1k_filtered_feature_bc_matrix/`. You can either copy the contents from the alignment folder to the analyis one, or you can just call the data on the original path. In this tutorial, I made a directory to keep all the files necessary to perform the analysis together (it can be very useful if you think about sharing your data with collaborators or when you are publishing).

**Question 1: What is the difference between `filtered_feature_bc_matrix` and `raw_feature_bc_matrix`?**

We will start by reading in the data. The `Read10X` function reads in the output of the cellranger pipeline from 10X, returning a unique molecular identified (UMI) count matrix. The values in this matrix represent the number of molecules for each feature (i.e. gene; row) that are detected in each cell (column).  

We next use the count matrix to create a `Seurat` object. The object serves as a container that contains both data (like the count matrix) and analysis (like PCA, or clustering results) for a single-cell dataset. If you curious to understand the structure of the `Seurat` object, they have a great [GitHub Wiki](https://github.com/satijalab/seurat/wiki) for developers.
  
```
#Install Seurat if you do not have it installed
install.packages('Seurat')
install.packages('patchwork') # great library to combine several ggplots into one graph.

#Load the packages necessary for this analysis
library(Seurat)
library(tidyverse)
library(patchwork) #you can also use cowplot::plot_grid if your prefer, but this one has some incredible features

#Load the neuron dataset
neuron.data <- Read10X(data.dir = ".")
# Initialize the Seurat object with the raw (non-normalized data).
neuron <- CreateSeuratObject(counts = neuron.data, project = "pbmc3k", min.cells = 3, min.features = 200)
# You can add metadata to your data here.
neuron
```  

**Question 2: Does your Seurat object detects the same number of cells that cellranger does? If not, what would be the reason?**

### Standard pre-processing workflow
The steps below encompass the standard pre-processing workflow for scRNA-seq data in Seurat. These represent the selection and filtration of cells based on QC metrics, data normalization and scaling, and the detection of highly variable features.

#### QC and selecting cells for further analysis
Seurat allows you to easily explore QC metrics and filter cells based on any user-defined criteria. A few QC metrics commonly used by the community include

* The number of unique genes detected in each cell.
    * Low-quality cells or empty droplets will often have very few genes
    * Cell doublets or multiplets may exhibit an aberrantly high gene count
* Similarly, the total number of molecules detected within a cell (correlates strongly with unique genes)
* The percentage of reads that map to the mitochondrial genome
    * Low-quality / dying cells often exhibit extensive mitochondrial contamination
    * We calculate mitochondrial QC metrics with the PercentageFeatureSet function, which calculates the percentage of counts originating from a set of features

```
# The [[ operator can add columns to object metadata. This is a great place to stash QC stats
neuron.1k[["percent.mt"]] <- PercentageFeatureSet(neuron.1k, pattern = "^mt-")
neuron.1k[["percent.hemo"]] <- PercentageFeatureSet(neuron.1k, pattern = "^Hbb-")

#Creating some QC plots and plotting them together
qc.featurerna.neuron1k <- VlnPlot(neuron.1k, features = "nFeature_RNA") + NoLegend() + 
  theme(axis.text.x = element_text(angle = 45, size = 10, hjust = 1)) + xlab("")

qc.nCountrna.neuron1k <- VlnPlot(neuron.1k, features = "nCount_RNA") + NoLegend() + 
  theme(axis.text.x = element_text(angle = 45, size = 10, hjust = 1)) + xlab("")

qc.percentMt.neuron1k <- VlnPlot(neuron.1k, features = "percent.mt") + NoLegend() + 
  theme(axis.text.x = element_text(angle = 45, size = 10, hjust = 1)) + xlab("")

qc.percentHemo.neuron1k <- VlnPlot(neuron.1k, features = "percent.hemo") + NoLegend() + 
  theme(axis.text.x = element_text(angle = 45, size = 10, hjust = 1)) + xlab("")

qc.count.featurerna.scatter.neuron.1k <- FeatureScatter(neuron.1k, feature1 = "nCount_RNA", feature2 = "nFeature_RNA", cols = "black") +
  NoLegend() + theme(axis.text.x = element_text(angle = 45, size = 12, hjust = 1)) + xlab("Total RNA reads") + 
  ylab("Number of expressed genes") + geom_point(fill="black", color = "black", shape = 15, size = 0.5)

qc.count.percentmt.scatter.neuron.1k <- FeatureScatter(neuron.1k, feature1 = "nCount_RNA", feature2 = "percent.mt", cols = "blue") +
  NoLegend() + theme(axis.text.x = element_text(angle = 45, size = 12, hjust = 1)) + xlab("Total RNA reads") + 
  ylab("Percent Mitochondrial Genes") + geom_point(fill="blue", color = "blue", shape = 23, size = 0.5)

qc.count.percenthemo.scatter.neuron.1k <- FeatureScatter(neuron.1k, feature1 = "nCount_RNA", feature2 = "percent.hemo")+ NoLegend() +
  theme(axis.text.x = element_text(angle = 45, size = 12, hjust = 1)) + xlab("Total RNA reads") + ylab("Percent Hemoglobin Beta") +
  geom_point(fill="red", color = "red",shape = 16, size = 0.5)

pdf(file = "./02_figures/2020.04.QCgraphs.neuron.1k.pdf")
(qc.featurerna.neuron1k | qc.nCountrna.neuron1k | qc.percentMt.neuron1k | qc.percentHemo.neuron1k) / (qc.count.featurerna.scatter.neuron.1k | qc.count.percentmt.scatter.neuron.1k | qc.count.percenthemo.scatter.neuron.1k)
dev.off()

# You can plot each graph individually here or copy the command inside the pdf to see the same graph that I will show you
# (qc.featurerna.neuron1k | qc.nCountrna.neuron1k | qc.percentMt.neuron1k | qc.percentHemo.neuron1k) / (qc.count.featurerna.scatter.neuron.1k | qc.count.percentmt.scatter.neuron.1k | qc.count.percenthemo.scatter.neuron.1k)
# qc.featurerna.neuron1k
# qc.nCountrna.neuron1k
# qc.percentMt.neuron1k
# qc.percentHemo.neuron1k
# qc.count.featurerna.scatter.neuron.1k
# qc.count.percentmt.scatter.neuron.1k
# qc.count.percenthemo.scatter.neuron.1k
```
** VERY IMPORTANT TO READ THE LITERATURE IN YOUR FIELD **
In this tutorial, we will filter out the cells that have:
1. Less than 200 genes and cells that have more than 5000 genes
2. More than 20% mitochondrial genes or 5% hemoglobin beta (this is very high, but this dataset has a lot of high mitochondrial expressing genes)

```
neuron.1k
neuron.1k <- subset(neuron.1k, subset = nFeature_RNA >= 200 & nFeature_RNA <= 5000 & 
                            percent.mt < 20 & percent.hemo < 5)
neuron.1k
```

### Normalizing the data and highly variable features/genes
After removing unwanted cells from the dataset, the next step is to normalize the data. By default, Seurat employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. Normalized values are stored in pbmc[["RNA"]]@data.

We next calculate a subset of features that exhibit high cell-to-cell variation in the dataset (i.e, they are highly expressed in some cells, and lowly expressed in others). It has been shown that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.

The method adopted in Seurat3, [described here](https://www.biorxiv.org/content/early/2018/11/02/460147.full.pdf), improves on previous versions by directly modeling the mean-variance relationship inherent in single-cell data, and is implemented in the `FindVariableFeatures` function. By default, 2,000 genes per dataset are selected. In this tutorial, I changed that parameter to include more genes (3,000). These will be used in downstream analysis, like PCA.
```
neuron.1k <- NormalizeData(neuron.1k, normalization.method = "LogNormalize", scale.factor = 10000)
neuron.1k <- FindVariableFeatures(neuron.1k, selection.method = "vst", nfeatures = 3000)

# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(neuron.1k), 10)

# plot variable features with and without labels
plot1 <- VariableFeaturePlot(neuron.1k)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot1 + plot2
```

### Scaling the data 
Next, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The `ScaleData` function:
* Shifts the expression of each gene, so that the mean expression across cells is 0
* Scales the expression of each gene, so that the variance across cells is 1
    * This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate
* The results of this are stored in `neuron.1k[["RNA"]]@scale.data`
```
all.genes <- rownames(neuron.1k)
#vars.to.regress is NOT a default argument, but since our sample has a lot of mitochondrial genes, is better to "regress them out"
neuron.1k <- ScaleData(neuron.1k, features = all.genes, vars.to.regress = "percent.mt")
```
**Question 3: In this tutorial, I asked to "regress out" mitochondrial contamination. Could you think one or more sources of variation that you may want to remove from your analysis?**

### Perform linear dimensional reduction
Next we perform PCA on the scaled data. By default, only the previously determined variable features are used as input, but can be defined using `features` argument if you wish to choose a different subset.

Seurat provides several useful ways of visualizing both cells and features that define the PCA, including `VizDimReduction`, `DimPlot`, and `DimHeatmap`.
```
neuron.1k <- RunPCA(neuron.1k, features = VariableFeatures(object = neuron.1k))
print(neuron.1k[["pca"]], dims = 1:5, nfeatures = 5)
VizDimLoadings(neuron.1k, dims = 1:2, reduction = "pca")
DimPlot(neuron.1k, reduction = "pca")
DimHeatmap(neuron.1k, dims = 1:10, cells = 500, balanced = TRUE)
DimHeatmap(neuron.1k, dims = 1, cells = 500, balanced = TRUE)
# You can save this graphs with the pdf commands above
```

### Determine the ‘dimensionality’ of the dataset
To overcome the extensive technical noise in any single feature for scRNA-seq data, Seurat clusters cells based on their PCA scores, with each PC essentially representing a ‘metafeature’ that combines information across a correlated feature set. The top principal components therefore represent a robust compression of the dataset. However, how many componenets should we choose to include? 10? 20? 100?

In [Macosko et al](https://www.cell.com/fulltext/S0092-8674(15)00549-8), Seurat implemented a resampling test inspired by the JackStraw procedure. We randomly permute a subset of the data (1% by default) and rerun PCA, constructing a ‘null distribution’ of feature scores, and repeat this procedure. We identify ‘significant’ PCs as those who have a strong enrichment of low p-value features.
```
# NOTE: This process can take a long time for big datasets, comment out for expediency. More
# approximate techniques such as those implemented in ElbowPlot() can be used to reduce
# computation time. In this example, we only do 100 replicates. Most papers will do at least 1000+
neuron.1k <- JackStraw(neuron.1k, num.replicate = 100)
neuron.1k <- ScoreJackStraw(neuron.1k, dims = 1:20)
JackStrawPlot(neuron.1k, dims = 1:20)
ElbowPlot(neuron.1k)
plot1 <- JackStrawPlot(neuron.1k, dims = 1:20)
plot2 <- ElbowPlot(neuron.1k)

pdf(file = "./02_figures/2020.04.jacksrawplot.elbow.plot.neuron.1k.pdf", width = 20)
plot1 + plot2
dev.off()

rm(plot1, plot2)
```

### Clustering the cells
Seurat v3 applies a graph-based clustering approach, building upon initial strategies in [Macosko et al](https://www.cell.com/fulltext/S0092-8674(15)00549-8). Importantly, the distance metric which drives the clustering analysis (based on previously identified PCs) remains the same. However, the approach to partioning the cellular distance matrix into clusters has dramatically improved. Their methods has been highly influenced by several papers in applied graph-based clustering in scRNA-seq and CyTOF data. Briefly, these methods embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected ‘quasi-cliques’ or ‘communities’.
```
neuron.1k <- FindNeighbors(neuron.1k, dims = 1:10)
neuron.1k <- FindClusters(neuron.1k, resolution = 0.5)
# Look at cluster IDs of the first 5 cells
head(Idents(neuron.1k), 5)
```

### Run non-linear dimensional reduction (UMAP/tSNE)
Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets. The goal of these algorithms is to learn the underlying manifold of the data in order to place similar cells together in low-dimensional space. Cells within the graph-based clusters determined above should co-localize on these dimension reduction plots. As input to the UMAP and tSNE, we suggest using the same PCs as input to the clustering analysis.

```
# If you haven't installed UMAP, you can do so via reticulate::py_install(packages =
# 'umap-learn')
neuron.1k <- RunUMAP(neuron.1k, dims = 1:10)
DimPlot(neuron.1k, reduction = "umap")
```
# Finding cluster biomarkers
Finding differentially expressed features (cluster biomarkers)
Seurat can help you find markers that define clusters via differential expression. By default, it identifes positive and negative markers of a single cluster (specified in `ident.1`), compared to all other cells. `FindAllMarkers` automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells.
```
# find all markers of cluster 1
cluster1.markers <- FindMarkers(neuron.1k, ident.1 = 1, min.pct = 0.25)
head(cluster1.markers, n = 5)
# find all markers distinguishing cluster 5 from clusters 0 and 3
cluster5.markers <- FindMarkers(neuron.1k, ident.1 = 5, ident.2 = c(0, 3), min.pct = 0.25)
head(cluster5.markers, n = 5)
# find markers for every cluster compared to all remaining cells, report only the positive ones
neuron.1k.markers <- FindAllMarkers(neuron.1k, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)
neuron.1k.markers %>% group_by(cluster) %>% top_n(n = 2, wt = avg_logFC)

cluster1.markers <- FindMarkers(neuron.1k, ident.1 = 0, logfc.threshold = 0.25, test.use = "roc", only.pos = TRUE)
```

This is a good place to save all your progress. You can save your file as such
```
saveRDS(neuron.1k, file = "./03_rds_files/neuron.1k_tutorial.rds")
```

Now, you can plot graphs that are unique to each cluster.  

**Question 4: Plot the violin and feature plot for the top marker gene for each cluster.**  

**Question 5: How could you "identify" what each cluster represents?**  

**Question 6: Create a document of your analysis and send it to me. You are welcome to "play" around with parameters and see how much different your final results are. If you choose something different, give me one or two sentences why the change in these parameters made biological sense.**

